{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LR_with_not_clean_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark --quiet\n",
        "!pip install -U -q PyDrive --quiet \n",
        "!apt install openjdk-8-jdk-headless &> /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKlaTB3lYNdK",
        "outputId": "b5e2972f-920e-4e34-bdaf-6bce30a639c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 281.4 MB 23 kB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 48.1 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sc = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()"
      ],
      "metadata": {
        "id": "rjXGhtPnY7p8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHpxHt06Y5Np",
        "outputId": "49514775-7234-4176-fb89-0ad9e42ba5c5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = sc.read \\\n",
        "  .option('header', 'True')\\\n",
        "  .option('inferSchema', 'True')\\\n",
        "  .option('sep', ',')\\\n",
        "  .csv('/content/drive/MyDrive/data.csv')"
      ],
      "metadata": {
        "id": "FFbXvgAkZQ4_"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Preprocessing"
      ],
      "metadata": {
        "id": "1lEJNPNuXs-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.where(data['Label'].isNull()== False)"
      ],
      "metadata": {
        "id": "QBpC_gwdWLpp"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.distinct()\n",
        "data.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLVxAw75CiK6",
        "outputId": "3c5340a1-afda-4beb-afd8-d466912e3a7d"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7630"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_cols = data.select(data.columns)\n",
        "data = my_cols.na.drop()"
      ],
      "metadata": {
        "id": "Q-qDQMZj17a-"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVY1De3aW9fv",
        "outputId": "943cf1d2-db50-4d61-e3ed-36c0c6dfc24d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['customerID',\n",
              " 'gender',\n",
              " 'Partner',\n",
              " 'Dependents',\n",
              " 'PhoneService',\n",
              " 'MultipleLines',\n",
              " 'InternetService',\n",
              " 'OnlineSecurity',\n",
              " 'OnlineBackup',\n",
              " 'DeviceProtection',\n",
              " 'TechSupport',\n",
              " 'StreamingTV',\n",
              " 'StreamingMovies',\n",
              " 'Contract',\n",
              " 'PaperlessBilling',\n",
              " 'PaymentMethod',\n",
              " 'Label']"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "numeric_features = ['SeniorCitizen', 'tenure', 'MonthlyCharges', 'TotalCharges']\n",
        "\n",
        "categorical_columns = []\n",
        "for col in data.columns:\n",
        "  if col not in numeric_features:\n",
        "    categorical_columns.append(col)\n",
        "\n",
        "categorical_columns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.where(data['Label'].isNull()== False)\n",
        "\n",
        "for column in categorical_columns:\n",
        "  data = data.na.fill(value=\" \",subset=[column])\n",
        "\n",
        "for column in numeric_features:\n",
        "  data = data.na.fill(value=0.0,subset=[column])"
      ],
      "metadata": {
        "id": "GN0FXJq8WZyH"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unimportant_features = ['StreamingTV']\n",
        "# data = data.drop(*tuple(unimportant_features))"
      ],
      "metadata": {
        "id": "yLLRgzx3Z7B1"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
        "                                OneHotEncoder,StringIndexer)\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "stages = []\n",
        "\n",
        "categorical_columns.remove('Label')\n",
        "\n",
        "for feature in categorical_columns:\n",
        "  stringIndexer = StringIndexer(inputCol=feature, outputCol=feature + 'Index')\n",
        "  encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()],outputCols=[feature + 'Vec'])\n",
        "  stages+=[stringIndexer, encoder]\n",
        "\n",
        "labelIndexer = StringIndexer(inputCol='Label', outputCol='label')\n",
        "stages += [labelIndexer]\n",
        "input_features = [c + 'Vec' for c in categorical_columns]+ numeric_features\n",
        "assembler = VectorAssembler(inputCols= input_features, outputCol='features')\n",
        "stages+=[assembler]\n",
        "\n",
        "pipeline = Pipeline(stages=stages)\n",
        "pipelineModel = pipeline.fit(data)\n",
        "assembler_df = pipelineModel.transform(data)"
      ],
      "metadata": {
        "id": "4KF1sPeQqH6F"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "log_reg= LogisticRegression(featuresCol='features',labelCol='label')\n",
        "\n",
        "train_data, test_data = assembler_df.randomSplit([0.8, 0.2])\n",
        "fit_model = log_reg.fit(train_data)\n",
        "results = fit_model.transform(test_data)"
      ],
      "metadata": {
        "id": "_TLfF3uJyioh"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
        "                                       labelCol='label')\n",
        "results.select('label','prediction')\n",
        "AUC = my_eval.evaluate(results)\n",
        "print(\"AUC score is : \",AUC)\n",
        "\n",
        "accuracy = results.filter(results.label == results.prediction).count() / float(results.count())\n",
        "print(\"Accuracy : \",accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLR1aR732non",
        "outputId": "0c3c9609-e753-435a-974c-98234a582274"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC score is :  0.6752841950861752\n",
            "Accuracy :  0.7641509433962265\n"
          ]
        }
      ]
    }
  ]
}